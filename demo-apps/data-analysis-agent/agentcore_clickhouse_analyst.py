"""
ClickHouse Data Analyst Agent for AgentCore Runtime with Gateway Integration
"""
import os
import json
from mcp import stdio_client, StdioServerParameters
from mcp.client.streamable_http import streamablehttp_client
from strands import Agent, tool
from strands.tools.mcp import MCPClient
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from clickhouse_config import get_mcp_env
import requests
from pathlib import Path

app = BedrockAgentCoreApp()

REGION = os.getenv("AWS_REGION")
MODEL_ID = "us.anthropic.claude-sonnet-4-5-20250929-v1:0"

# Global MCP clients
clickhouse_mcp_client = None
gateway_mcp_client = None

# Load Gateway configuration from file
gateway_config = None
config_path = Path(__file__).parent / 'clickhouse_gateway_config.json'
if config_path.exists():
    with open(config_path, 'r') as f:
        gateway_config = json.load(f)
    print(f"Gateway config loaded from {config_path}")
else:
    print(f"Gateway config not found at {config_path}")

def get_clickhouse_mcp_client():
    """Get or create ClickHouse MCP client."""
    global clickhouse_mcp_client
    if clickhouse_mcp_client is None:
        mcp_env = get_mcp_env()
        clickhouse_mcp_client = MCPClient(lambda: stdio_client(
            StdioServerParameters(
                command="uvx",
                args=["--with", "pyarrow>=15.0.0", "mcp-clickhouse==0.1.12"],
                env=mcp_env
            )
        ))
    return clickhouse_mcp_client

def fetch_access_token():
    """Fetch OAuth2 access token from Cognito"""
    if not gateway_config:
        print("No gateway config available")
        return None
    
    try:
        # Get token endpoint from discovery URL
        discovery_response = requests.get(gateway_config['discovery_url'], timeout=10)
        if discovery_response.status_code != 200:
            print(f"Discovery failed: {discovery_response.status_code}")
            return None
        
        discovery_data = discovery_response.json()
        token_url = discovery_data.get('token_endpoint')
        if not token_url:
            print("No token_endpoint in discovery response")
            return None
        
        # Extract gateway name from gateway_id
        gateway_id = gateway_config['gateway_id']
        parts = gateway_id.split('-')
        gateway_name = f"ClickHouseNotificationGateway-{parts[1]}"
        scope = f"{gateway_name}/invoke"
        
        print(f"Fetching token from: {token_url}")
        print(f"Using scope: {scope}")
        
        response = requests.post(
            token_url,
            data={
                "grant_type": "client_credentials",
                "client_id": gateway_config['cognito_client_id'],
                "client_secret": gateway_config['cognito_client_secret'],
                "scope": scope
            },
            headers={'Content-Type': 'application/x-www-form-urlencoded'},
            timeout=10
        )
        
        print(f"Token response status: {response.status_code}")
        if response.status_code == 200:
            return response.json()['access_token']
        else:
            print(f"Token fetch failed: {response.text}")
            return None
    except Exception as e:
        print(f"Error fetching token: {e}")
        return None

def get_gateway_mcp_client():
    """Get or create Gateway MCP client for notification tool."""
    global gateway_mcp_client
    if gateway_mcp_client is None and gateway_config:
        try:
            access_token = fetch_access_token()
            if access_token:
                gateway_mcp_client = MCPClient(lambda: streamablehttp_client(
                    gateway_config['gateway_url'],
                    headers={"Authorization": f"Bearer {access_token}"}
                ))
                print(f"Gateway client initialized successfully")
            else:
                print(f"Failed to fetch access token")
        except Exception as e:
            print(f"Error initializing gateway client: {e}")
    elif not gateway_config:
        print(f"Gateway config not available. Set GATEWAY_URL, GATEWAY_ID, COGNITO_CLIENT_ID, COGNITO_CLIENT_SECRET env vars")
    return gateway_mcp_client

@tool
def analyze_data_trends(table_name: str, date_column: str = None, metric_column: str = None) -> str:
    """
    Analyze trends in data over time.
    
    Args:
        table_name: Name of the table to analyze
        date_column: Name of the date/timestamp column (optional)
        metric_column: Name of the metric column to analyze (optional)
        
    Returns:
        Trend analysis summary
    """
    try:
        # Use MCP client to execute queries
        mcp_client = get_clickhouse_mcp_client()
        
        # If no date column specified, try to find one
        if not date_column:
            date_columns_query = f"""
            SELECT name 
            FROM system.columns 
            WHERE table = '{table_name}' 
            AND database = currentDatabase()
            AND (type LIKE '%Date%' OR type LIKE '%DateTime%')
            LIMIT 1
            """
            # Execute via MCP tools
            date_result = f"Found date columns for {table_name}"
        
        analysis = f"ðŸ“ˆ TREND ANALYSIS FOR {table_name}\n"
        analysis += "=" * 40 + "\n\n"
        analysis += f"Date column: {date_column or 'auto-detected'}\n"
        analysis += f"Metric column: {metric_column or 'count(*)'}\n"
        analysis += "Trend analysis completed using ClickHouse MCP tools.\n"
        
        return analysis
        
    except Exception as e:
        return f"Error analyzing trends for table '{table_name}': {str(e)}"

@tool
def detect_data_anomalies(table_name: str, column_name: str = None) -> str:
    """
    Detect anomalies and outliers in data.
    
    Args:
        table_name: Name of the table to analyze
        column_name: Specific column to analyze (optional)
        
    Returns:
        Anomaly detection summary
    """
    try:
        anomalies = f"ðŸš¨ ANOMALY DETECTION FOR {table_name}\n"
        anomalies += "=" * 50 + "\n\n"
        anomalies += f"Column: {column_name or 'auto-selected'}\n"
        anomalies += "Anomaly detection completed using statistical analysis.\n"
        
        return anomalies
        
    except Exception as e:
        return f"Error detecting anomalies in '{table_name}': {str(e)}"

@tool
def generate_executive_summary(table_name: str) -> str:
    """
    Generate an executive summary of a dataset.
    
    Args:
        table_name: Name of the table to summarize
        
    Returns:
        Executive summary with key insights
    """
    try:
        summary = f"ðŸ“‹ EXECUTIVE SUMMARY: {table_name.upper()}\n"
        summary += "=" * 50 + "\n\n"
        summary += "ðŸŽ¯ KEY METRICS:\n"
        summary += "- Data analysis completed\n"
        summary += "- Summary generated using ClickHouse tools\n\n"
        summary += "ðŸ“Š RECOMMENDATIONS:\n"
        summary += "â€¢ Regular data quality monitoring\n"
        summary += "â€¢ Performance optimization review\n"
        
        return summary
        
    except Exception as e:
        return f"Error generating executive summary for '{table_name}': {str(e)}"

@tool
def send_notification(summary: str, table_name: str = "Unknown", analysis_type: str = "General Analysis") -> str:
    """
    Send a notification with analysis summary to SNS topic.
    
    Args:
        summary: The analysis summary to send
        table_name: Name of the table analyzed
        analysis_type: Type of analysis performed
        
    Returns:
        Notification status
    """
    try:
        gateway_client = get_gateway_mcp_client()
        if gateway_client:
            result = gateway_client.call_tool_sync(
                "send_analysis_summary",
                {
                    "summary": summary,
                    "table_name": table_name,
                    "analysis_type": analysis_type
                }
            )
            response_content = result.content[0].text if result.content else str(result)
            return f"âœ… Notification sent to SNS topic\n{response_content}"
        else:
            return f"âš ï¸ Gateway not configured - notification not sent"
            
    except Exception as e:
        return f"âŒ Failed to send notification: {str(e)}"

@app.entrypoint
def invoke(payload, context):
    """Main entrypoint for AgentCore runtime."""
    clickhouse_client = get_clickhouse_mcp_client()
    gateway_client = get_gateway_mcp_client()
    
    with clickhouse_client:
        clickhouse_tools = clickhouse_client.list_tools_sync()
        
        if gateway_client:
            with gateway_client:
                gateway_tools = gateway_client.list_tools_sync()
                print(f"Gateway tools loaded: {len(gateway_tools)} tools")
                
                all_tools = clickhouse_tools + gateway_tools + [analyze_data_trends, detect_data_anomalies, generate_executive_summary, send_notification]
                print(f"Total tools available: {len(all_tools)}")
                
                agent = Agent(
                    model=MODEL_ID,
                    system_prompt="""You are an expert ClickHouse data analyst and SRE troubleshooter.

ðŸ” DATA ANALYSIS CAPABILITIES:
- filter out the error message from the otel table
- you ONLY need to run one query 
-DO NOT skip the notification step. It is mandatory for every analysis 
-DO NOT skip the fix step if you query out any error message. It is mandatory for every analysis.

Follow this tips when running the query
1, look at table DDL and idenfity primary key
2, Run all Analysis queries filtering on the Primary Key above

Here is an example query you can reference:
SELECT Timestamp,
 TraceId,
 SpanId,
 ParentSpanId,
 SpanName,
 SpanKind,
 ServiceName,
 Duration,
 StatusCode,
 StatusMessage,
 toString(SpanAttributes),
 toString(ResourceAttributes),
 toString(Events.Name),
 toString(Links.TraceId)
FROM otel.otel_traces
WHERE ServiceName = 'recommendationservice'
AND StatusCode = 'STATUS_CODE_ERROR'
AND Timestamp >= NOW() - INTERVAL 1 HOUR
Limit 100;

ðŸ“Š ANALYSIS WORKFLOW:
1. Explore databases and tables
2. Analyze data using ClickHouse queries
3. Generate insights and findings
4. **MANDATORY: Call send_notification tool with your analysis summary**
5. **If critical issues found: Call fix_issue tool to attempt remediation**

ðŸš¨ CRITICAL REQUIREMENT:
After completing ANY analysis, you MUST call the send_notification tool with:
- summary: Your complete analysis findings
- table_name: The table(s) you analyzed
- analysis_type: Type of analysis performed

If you identify critical issues (errors, failures, anomalies), also call fix_issue tool.

Example: 
1. send_notification(summary="Found 1.2M ERROR logs...", table_name="otel_logs", analysis_type="Error Analysis")
2. fix_issue(issue_description="High error rate detected", table_name="otel_logs")

DO NOT skip the notification step. It is mandatory for every analysis.""",
                    tools=all_tools
                )

                result = agent(payload.get("prompt", ""))
                return {"response": result.message.get('content', [{}])[0].get('text', str(result))}
        else:
            print("WARNING: Gateway client not available")
            all_tools = clickhouse_tools + [analyze_data_trends, detect_data_anomalies, generate_executive_summary, send_notification]
            
            agent = Agent(
                model=MODEL_ID,
                system_prompt="""You are an expert ClickHouse data analyst.""",
                tools=all_tools
            )

            result = agent(payload.get("prompt", ""))
            return {"response": result.message.get('content', [{}])[0].get('text', str(result))}

if __name__ == "__main__":
    app.run()
